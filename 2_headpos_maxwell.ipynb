{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0739274d-8acf-4e4b-9367-95bfaaf7475e",
   "metadata": {},
   "source": [
    "## Perform Signal-Space Separation (SSS) and Maxwell filtering\n",
    "\n",
    "This step performs Maxwell filtering with tSSS (10 s window) on each run to suppress environmental noise, sensor cross-talk, and head-movement–related artifacts using site-specific calibration (`sss_cal.dat`) and cross-talk (`ct_sparse.fif`) files. Data from every run are transformed to a common head position (the first run’s `dev_head_t`) to standardize head geometry across runs. Each filtered run is saved (`_sss_raw.fif`). The filtered runs are then concatenated into a single continuous Raw object (`_ALL_sss_raw.fif`). *This is the file that should be fed into ICA in the next step.*\n",
    "\n",
    "#### What's tSSS?\n",
    "Signal Space Separation (SSS) is a Maxwell-equation–based method that expands MEG sensor data into spherical-harmonic components originating inside vs. outside the helmet. By modeling the magnetic field, SSS retains “internal” brain sources and suppresses “external” interference; temporal SSS (tSSS) further rejects artifacts by removing components whose time courses match external sources across a sliding window. Here, SSS/tSSS are applied with site calibration and cross-talk files, data are transformed to the first run’s head position, each run is saved, then all runs are concatenated for analysis.\n",
    "\n",
    "*Requires unfiltered data and calibration files (sss_cal.dat, ct_sparse.fif)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec292805-7b74-4656-a9c2-4e50cc9bcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.io import read_raw_fif\n",
    "from mne.chpi import compute_chpi_amplitudes, compute_chpi_locs, compute_head_pos\n",
    "from mne.preprocessing import maxwell_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e566ace6-069a-45b2-af9f-0361064c6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session info\n",
    "subject = 'nbl_005'\n",
    "session = '01'\n",
    "files = ['bigfrank_1', 'bigfrank_2', 'bigfrank_3'] # 'pharyperc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f333168f-e42c-4320-be5a-89584e499a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad channels: ['MEG1132', 'MEG1543', 'MEG1843']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/sphere/nbl/processed_meg/nbl_005/ses-01/nbl_005_bigfrank_1_raw.fif',\n",
       " '/mnt/sphere/nbl/processed_meg/nbl_005/ses-01/nbl_005_bigfrank_2_raw.fif',\n",
       " '/mnt/sphere/nbl/processed_meg/nbl_005/ses-01/nbl_005_bigfrank_3_raw.fif']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file paths\n",
    "processed_meg_dir = '/mnt/sphere/nbl/processed_meg/'\n",
    "sub_ses = os.path.join(subject, 'ses-'+session)\n",
    "bads_list_fname = os.path.join(processed_meg_dir, sub_ses, subject+'_bads.txt')\n",
    "with open(bads_list_fname, 'r') as f: bads = [line.strip() for line in f.readlines()]\n",
    "print('Bad channels:',bads)\n",
    "raw_fnames = [os.path.join(processed_meg_dir, sub_ses, subject+'_'+f+'_raw.fif') for f in files]\n",
    "raw_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d60da2-b29d-4bc9-8540-74e66f550259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing file 1/3: nbl_005_bigfrank_1_raw.fif\n",
      "============================================================\n",
      "Loading raw file...\n",
      "Loading took 35.1 seconds\n",
      "File 1 head position:\n",
      "[[ 9.93479133e-01  1.12533905e-01  1.83216333e-02  4.51840140e-04]\n",
      " [-1.13874041e-01  9.71344590e-01  2.08621070e-01  3.66337656e-04]\n",
      " [ 5.68032172e-03 -2.09346995e-01  9.77825046e-01  5.56054749e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "============================================================\n",
      "Processing file 2/3: nbl_005_bigfrank_2_raw.fif\n",
      "============================================================\n",
      "Loading raw file...\n",
      "Loading took 30.6 seconds\n",
      "File 2 head position:\n",
      "[[ 0.99439013  0.09942237  0.03610669 -0.00182439]\n",
      " [-0.10572225  0.94504142  0.30938619  0.00356152]\n",
      " [-0.00336241 -0.31146783  0.95025086  0.05918203]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "============================================================\n",
      "Processing file 3/3: nbl_005_bigfrank_3_raw.fif\n",
      "============================================================\n",
      "Loading raw file...\n",
      "Loading took 34.8 seconds\n",
      "File 3 head position:\n",
      "[[ 0.9985922   0.05205923  0.01015389 -0.00394523]\n",
      " [-0.05130173  0.99660903 -0.0643286  -0.00369065]\n",
      " [-0.01346836  0.06371713  0.99787694  0.05645259]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load raw files and static head positions\n",
    "raw_list = []\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    fname = os.path.join(processed_meg_dir, sub_ses, f\"{subject}_{file}_raw.fif\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing file {idx+1}/{len(files)}: {os.path.basename(fname)}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # load raw data\n",
    "    print(f\"Loading raw file...\")\n",
    "    t = time.time()\n",
    "    raw = read_raw_fif(fname, preload=True, verbose=False)\n",
    "    raw.info[\"bads\"] = bads  # important!\n",
    "    print(f\"Loaded in {time.time() - t:.1f} seconds.\\n\")\n",
    "    \n",
    "    raw_list.append(raw)\n",
    "    \n",
    "    print(f\"File {idx+1} head position:\")\n",
    "    print(raw.info['dev_head_t']['trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77413a14-e0f7-48b2-9561-e579217cb8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Maxwell filter\n",
    "cal_fname = '/mnt/sphere/nbl/sss/sss_cal.dat'   # calibration file\n",
    "ct_fname = '/mnt/sphere/nbl/sss/ct_sparse.fif'  # cross-talk file\n",
    "\n",
    "# process each file with Maxwell filtering & transform to initial head position\n",
    "destination = raw_list[0].info['dev_head_t']\n",
    "raw_sss_list = []\n",
    "for idx, (file, raw) in enumerate(zip(files, raw_list)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Maxwell filtering file {idx+1}/3: {subject}_{file}_raw.fif\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Applying Maxwell filter with tSSS...\")\n",
    "    t = time.time()\n",
    "    raw_sss = maxwell_filter(raw, cross_talk=ct_fname, calibration=cal_fname, destination=destination,\n",
    "                             st_duration=10, origin=(0., 0., 0.04), verbose=True)\n",
    "    elapsed = time.time() - t\n",
    "    print(f\"Maxwell filtering completed in {elapsed:.1f} seconds\")\n",
    "    if len(raw.ch_names) != len(raw_sss.ch_names):\n",
    "        raise RuntimeError(f\"Lost channels: Raw has {len(raw.ch_names)} channels; Raw_sss has {len(raw_sss.ch_names)} channels\")\n",
    "    \n",
    "    # save\n",
    "    sss_fname = os.path.join(processed_meg_dir, sub_ses, f\"{subject}_{file}_sss_raw.fif\")\n",
    "    raw_sss.save(sss_fname, overwrite=True)\n",
    "    print(f\"Saved to: {sss_fname}\")\n",
    "    \n",
    "    raw_sss_list.append(raw_sss)\n",
    "\n",
    "# concatenate all Maxwell filtered files\n",
    "raw_concat = mne.concatenate_raws(raw_sss_list, preload=True)\n",
    "print(f\"Concatenated data:\")\n",
    "print(f\"  Duration: {raw_concat.times[-1]:.1f} seconds ({raw_concat.times[-1]/60:.1f} minutes)\")\n",
    "print(f\"  Samples: {len(raw_concat.times)}\")\n",
    "print(f\"  Channels: {len(raw_concat.copy().pick('meg').ch_names)} MEG, \")\n",
    "\n",
    "# save concatenated file\n",
    "concat_fname = os.path.join(processed_meg_dir, sub_ses, f\"{subject}_ALL_sss_raw.fif\")\n",
    "raw_concat.save(concat_fname, overwrite=True)\n",
    "print(f\"\\nSaved concatenated file to: {concat_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586a890-4791-45d8-848b-08696916a4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
